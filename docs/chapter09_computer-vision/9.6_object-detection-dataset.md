# 9.6 ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ˆçš®å¡ä¸˜ï¼‰


```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import math
%matplotlib inline
```

    TensorFlow 2.x selected.
    

åœ¨ç›®æ ‡æ£€æµ‹é¢†åŸŸå¹¶æ²¡æœ‰ç±»ä¼¼MNISTæˆ–Fashion-MNISTé‚£æ ·çš„å°æ•°æ®é›†ã€‚ä¸ºäº†å¿«é€Ÿæµ‹è¯•æ¨¡å‹ï¼Œæˆ‘ä»¬åˆæˆäº†ä¸€ä¸ªå°çš„æ•°æ®é›†ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ä¸€ä¸ªå¼€æºçš„çš®å¡ä¸˜3Dæ¨¡å‹ç”Ÿæˆäº†1,000å¼ ä¸åŒè§’åº¦å’Œå¤§å°çš„çš®å¡ä¸˜å›¾åƒã€‚ç„¶åæˆ‘ä»¬æ”¶é›†äº†ä¸€ç³»åˆ—èƒŒæ™¯å›¾åƒï¼Œå¹¶åœ¨æ¯å¼ å›¾çš„éšæœºä½ç½®æ”¾ç½®ä¸€å¼ éšæœºçš„çš®å¡ä¸˜å›¾åƒã€‚

## 9.6.1 ä¸‹è½½æ•°æ®é›†

## ä¸‹è½½çš®å¡ä¸˜


```python

!pip install mxnet
from tqdm import tqdm
import matplotlib.pyplot as plt
from mxnet.gluon import utils as gutils # pip install mxnet
from mxnet import image
import os
import json

data_dir = 'data/pikachu'
os.makedirs(data_dir, exist_ok=True)

# 1. ä¸‹è½½åŸå§‹æ•°æ®é›†
# è§http://zh.d2l.ai/chapter_computer-vision/object-detection-dataset.html
def _download_pikachu(data_dir):
    root_url = ('https://apache-mxnet.s3-accelerate.amazonaws.com/'
                'gluon/dataset/pikachu/')
    dataset = {'train.rec': 'e6bcb6ffba1ac04ff8a9b1115e650af56ee969c8',
               'train.idx': 'dcf7318b2602c06428b9988470c731621716c393',
               'val.rec': 'd6c33f799b4d058e82f2cb5bd9a976f69d72d520'}
    for k, v in dataset.items():
        gutils.download(root_url + k, os.path.join(data_dir, k), sha1_hash=v)

if not os.path.exists(os.path.join(data_dir, "train.rec")):
    print("ä¸‹è½½åŸå§‹æ•°æ®é›†åˆ°%s..." % data_dir)
    _download_pikachu(data_dir)

# 2. MXNetæ•°æ®è¿­ä»£å™¨
def load_data_pikachu(batch_size, edge_size=256):  # edge_sizeï¼šè¾“å‡ºå›¾åƒçš„å®½å’Œé«˜
    train_iter = image.ImageDetIter(
        path_imgrec=os.path.join(data_dir, 'train.rec'),
        path_imgidx=os.path.join(data_dir, 'train.idx'),
        batch_size=batch_size,
        data_shape=(3, edge_size, edge_size),  # è¾“å‡ºå›¾åƒçš„å½¢çŠ¶
#         shuffle=False,  # ä»¥éšæœºé¡ºåºè¯»å–æ•°æ®é›†
#         rand_crop=1,  # éšæœºè£å‰ªçš„æ¦‚ç‡ä¸º1
        min_object_covered=0.95, max_attempts=200)
    val_iter = image.ImageDetIter(
        path_imgrec=os.path.join(data_dir, 'val.rec'), batch_size=batch_size,
        data_shape=(3, edge_size, edge_size), shuffle=False)
    return train_iter, val_iter

batch_size, edge_size = 1, 256
train_iter, val_iter = load_data_pikachu(batch_size, edge_size)
batch = train_iter.next()
batch.data[0][0].shape, batch.label[0][0].shape

# 3. è½¬æ¢æˆPNGå›¾ç‰‡å¹¶ä¿å­˜
def process(data_iter, save_dir):
    """batch size == 1"""
    data_iter.reset() # ä»å¤´å¼€å§‹
    all_label = dict()
    id = 1
    os.makedirs(os.path.join(save_dir, 'images'), exist_ok=True)
    for sample in tqdm(data_iter):
        x = sample.data[0][0].asnumpy().transpose((1,2,0))
        plt.imsave(os.path.join(save_dir, 'images', str(id) + '.png'), x / 255.0)

        y = sample.label[0][0][0].asnumpy()

        label = {}
        label["class"] = int(y[0])
        label["loc"] = y[1:].tolist()

        all_label[str(id) + '.png'] = label.copy()

        id += 1

    with open(os.path.join(save_dir, 'label.json'), 'w') as f:
        json.dump(all_label, f, indent=True)

process(data_iter = train_iter, save_dir = os.path.join(data_dir, "train"))
process(data_iter = val_iter, save_dir = os.path.join(data_dir, "val"))
```

    Collecting mxnet
    [?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68.7MB 54kB/s 
    [?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)
    Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.1)
    Collecting graphviz<0.9.0,>=0.8.1
      Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.11.28)
    Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)
    Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)
    Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)
    Installing collected packages: graphviz, mxnet
      Found existing installation: graphviz 0.10.1
        Uninstalling graphviz-0.10.1:
          Successfully uninstalled graphviz-0.10.1
    Successfully installed graphviz-0.8.4 mxnet-1.6.0
    ä¸‹è½½åŸå§‹æ•°æ®é›†åˆ°data/pikachu...
    Downloading data/pikachu/train.rec from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/train.rec...
    Downloading data/pikachu/train.idx from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/train.idx...
    Downloading data/pikachu/val.rec from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/val.rec...
    

    900it [00:54, 16.58it/s]
    100it [00:06, 16.24it/s]
    

## å¯¼å…¥ç›¸å…³åº“


```python
from PIL import Image
import sys
sys.path.append("..")

data_dir = "data/pikachu"

assert os.path.exists(os.path.join(data_dir, "train"))
```

## 9.6.2 è¯»å–æ•°æ®é›†

æˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸ªæ•°æ®é›†ç±»PikachuDetDatasetï¼Œæ•°æ®é›†æ¯ä¸ªæ ·æœ¬åŒ…å«labelå’Œimageï¼Œå…¶ä¸­labelæ˜¯ä¸€ä¸ª mÃ—5mÃ—5 çš„å‘é‡ï¼Œå³mä¸ªè¾¹ç•Œæ¡†ï¼Œæ¯ä¸ªè¾¹ç•Œæ¡†ç”±[class, x_min, y_min, x_max, y_max]è¡¨ç¤ºï¼Œè¿™é‡Œçš„çš®å¡ä¸˜æ•°æ®é›†ä¸­æ¯ä¸ªå›¾åƒåªæœ‰ä¸€ä¸ªè¾¹ç•Œæ¡†ï¼Œå› æ­¤m=1ã€‚imageæ˜¯ä¸€ä¸ªæ‰€æœ‰å…ƒç´ éƒ½ä½äº[0.0, 1.0]çš„æµ®ç‚¹tensorï¼Œä»£è¡¨å›¾ç‰‡æ•°æ®ã€‚


```python
# çš®å¡ä¸˜æ£€æµ‹æ•°æ®é›†ç±»
# è¿™é‡Œå’Œpytorchç‰ˆæœ¬ä¸å¯¹åº”ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å–å‡ºæ‰€æœ‰çš„imageså’Œlabelsï¼Œæ¥ç”Ÿæˆæ•°æ®é›†
def generatorPikachuDataset(data_dir, part, image_size=(256, 256)):
    image_dir = os.path.join(data_dir, part, "images")
    with open(os.path.join(data_dir, part, "label.json")) as f:
        label = json.load(f)
    
    image = []
    labels = []
    for index in range(len(label)):
        image_path = str(index + 1) + ".png"

        cls = label[image_path]["class"]
        # 
        lab = np.array([cls] + label[image_path]["loc"],
                    dtype="float32")
        labels.append(lab)

        img = tf.io.read_file(os.path.join(image_dir, image_path))
        # è¾“å‡ºä¸ºä¸‰é€šé“
        img = tf.image.decode_png(img, channels=3)
        # æ”¹å˜ç±»å‹é¡ºä¾¿å½’ä¸€åŒ–
        img = tf.image.convert_image_dtype(img, dtype=tf.float32)
        # æ›´æ”¹å›¾åƒçš„å¤§å°
        img = tf.image.resize(img, size=image_size)
        image.append(img)

    return image, labels
```


```python

path = tf.strings.join([data_dir, "train", "images", "1.png"], separator='/')
img = tf.io.read_file(path)
img = tf.image.decode_png(img, channels=3)
img = tf.image.convert_image_dtype(img, dtype=tf.float32)
img = tf.image.resize(img, size=(256,256))
print(img.shape)
print(img[0][0])
plt.imshow(img)
```

    (256, 256, 3)
    tf.Tensor([0.56078434 0.5647059  0.58431375], shape=(3,), dtype=float32)
    




    <matplotlib.image.AxesImage at 0x7f10985cce10>




![png](../img/chapter09/9.6/output_11_2.png)


ç„¶åæˆ‘ä»¬é€šè¿‡åˆ›å»ºDataLoaderå®ä¾‹æ¥è¯»å–ç›®æ ‡æ£€æµ‹æ•°æ®é›†ã€‚æˆ‘ä»¬å°†ä»¥éšæœºé¡ºåºè¯»å–è®­ç»ƒæ•°æ®é›†ï¼ŒæŒ‰åºè¯»å–æµ‹è¯•æ•°æ®é›†ã€‚

*åŸä¹¦è¿˜åšäº†æ•°æ®å¢å¼º: å¯¹äºè®­ç»ƒé›†ä¸­çš„æ¯å¼ å›¾åƒï¼Œæˆ‘ä»¬å°†é‡‡ç”¨éšæœºè£å‰ªï¼Œå¹¶è¦æ±‚è£å‰ªå‡ºçš„å›¾åƒè‡³å°‘è¦†ç›–æ¯ä¸ªç›®æ ‡95%çš„åŒºåŸŸã€‚ç”±äºè£å‰ªæ˜¯éšæœºçš„ï¼Œè¿™ä¸ªè¦æ±‚ä¸ä¸€å®šæ€»è¢«æ»¡è¶³ã€‚æˆ‘ä»¬è®¾å®šæœ€å¤šå°è¯•200æ¬¡éšæœºè£å‰ªï¼šå¦‚æœéƒ½ä¸ç¬¦åˆè¦æ±‚åˆ™ä¸è£å‰ªå›¾åƒã€‚ä¸ºä¿è¯è¾“å‡ºç»“æœçš„ç¡®å®šæ€§ï¼Œæˆ‘ä»¬ä¸éšæœºè£å‰ªæµ‹è¯•æ•°æ®é›†ä¸­çš„å›¾åƒã€‚ æˆ‘ä»¬ä¹Ÿæ— é¡»æŒ‰éšæœºé¡ºåºè¯»å–æµ‹è¯•æ•°æ®é›†ã€‚*


```python

def load_data_pikachu(batch_size, edge_size=256, data_dir="data/pikachu"):
    """edge_sizeï¼šè¾“å‡ºå›¾åƒçš„å®½å’Œé«˜"""
    image_size = (edge_size, edge_size)

    def load_dataset(part):
        images, labels = generatorPikachuDataset(data_dir, part, image_size)

        dataset = tf.data.Dataset.from_tensor_slices((images, labels))
        dataset = dataset.shuffle(len(labels))
        dataset = dataset.batch(batch_size).prefetch(1)
        return dataset

    train_dataset = load_dataset("train")
    val_dataset = load_dataset("val")

    return train_dataset, val_dataset
```

ä¸‹é¢æˆ‘ä»¬è¯»å–ä¸€ä¸ªå°æ‰¹é‡å¹¶æ‰“å°å›¾åƒå’Œæ ‡ç­¾çš„å½¢çŠ¶ã€‚å›¾åƒçš„å½¢çŠ¶å’Œä¹‹å‰å®éªŒä¸­çš„ä¸€æ ·ï¼Œä¾ç„¶æ˜¯pytorch(æ‰¹é‡å¤§å°, é€šé“æ•°, é«˜, å®½) tensorflowä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œé«˜ï¼Œå®½ï¼Œé€šé“æ•°ï¼‰ã€‚è€Œæ ‡ç­¾çš„å½¢çŠ¶åˆ™æ˜¯(æ‰¹é‡å¤§å°, m, 5)ï¼Œå…¶ä¸­mç­‰äºæ•°æ®é›†ä¸­å•ä¸ªå›¾åƒæœ€å¤šå«æœ‰çš„è¾¹ç•Œæ¡†ä¸ªæ•°ã€‚å°æ‰¹é‡è®¡ç®—è™½ç„¶é«˜æ•ˆï¼Œä½†å®ƒè¦æ±‚æ¯å¼ å›¾åƒå«æœ‰ç›¸åŒæ•°é‡çš„è¾¹ç•Œæ¡†ï¼Œä»¥ä¾¿æ”¾åœ¨åŒä¸€ä¸ªæ‰¹é‡ä¸­ã€‚ç”±äºæ¯å¼ å›¾åƒå«æœ‰çš„è¾¹ç•Œæ¡†ä¸ªæ•°å¯èƒ½ä¸åŒï¼Œæˆ‘ä»¬ä¸ºè¾¹ç•Œæ¡†ä¸ªæ•°å°äºmmçš„å›¾åƒå¡«å……éæ³•è¾¹ç•Œæ¡†ï¼Œç›´åˆ°æ¯å¼ å›¾åƒå‡å«æœ‰mä¸ªè¾¹ç•Œæ¡†ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ¯æ¬¡è¯»å–å°æ‰¹é‡çš„å›¾åƒäº†ã€‚å›¾åƒä¸­æ¯ä¸ªè¾¹ç•Œæ¡†çš„æ ‡ç­¾ç”±é•¿åº¦ä¸º5çš„æ•°ç»„è¡¨ç¤ºã€‚æ•°ç»„ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯è¾¹ç•Œæ¡†æ‰€å«ç›®æ ‡çš„ç±»åˆ«ã€‚å½“å€¼ä¸º-1æ—¶ï¼Œè¯¥è¾¹ç•Œæ¡†ä¸ºå¡«å……ç”¨çš„éæ³•è¾¹ç•Œæ¡†ã€‚æ•°ç»„çš„å‰©ä½™4ä¸ªå…ƒç´ åˆ†åˆ«è¡¨ç¤ºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„xxå’Œyyè½´åæ ‡ä»¥åŠå³ä¸‹è§’çš„xxå’Œyyè½´åæ ‡ï¼ˆå€¼åŸŸåœ¨0åˆ°1ä¹‹é—´ï¼‰ã€‚è¿™é‡Œçš„çš®å¡ä¸˜æ•°æ®é›†ä¸­æ¯ä¸ªå›¾åƒåªæœ‰ä¸€ä¸ªè¾¹ç•Œæ¡†ï¼Œå› æ­¤m=1ã€‚


```python
batch_size =  32
edge_size = 256

train_dataset, val_dataset = load_data_pikachu(batch_size, edge_size, data_dir)
train_dataset, val_dataset
```




    (<PrefetchDataset shapes: ((None, 256, 256, 3), (None, 5)), types: (tf.float32, tf.float32)>,
     <PrefetchDataset shapes: ((None, 256, 256, 3), (None, 5)), types: (tf.float32, tf.float32)>)



## 9.6.3 å›¾ç¤ºæ•°æ®

æˆ‘ä»¬ç”»å‡º10å¼ å›¾åƒå’Œå®ƒä»¬ä¸­çš„è¾¹ç•Œæ¡†ã€‚å¯ä»¥çœ‹åˆ°ï¼Œçš®å¡ä¸˜çš„è§’åº¦ã€å¤§å°å’Œä½ç½®åœ¨æ¯å¼ å›¾åƒä¸­éƒ½ä¸ä¸€æ ·ã€‚å½“ç„¶ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•çš„äººå·¥æ•°æ®é›†ã€‚å®é™…ä¸­çš„æ•°æ®é€šå¸¸ä¼šå¤æ‚å¾—å¤šã€‚


```python
item = next(iter(train_dataset))
print(item[0].numpy().shape, item[1].numpy().shape)
```

    (32, 256, 256, 3) (32, 5)
    


```python
imgs = item[0][0:10]
bboxes = item[1][0:10, 1:]

axes = show_images(imgs, 2, 5).flatten()
for ax, bb in zip(axes, bboxes):
    show_bboxes(ax, [bb*edge_size], colors=['w'])
```


![png](../img/chapter09/9.6/output_20_0.png)


## å°ç»“

* åˆæˆçš„çš®å¡ä¸˜æ•°æ®é›†å¯ç”¨äºæµ‹è¯•ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚
* ç›®æ ‡æ£€æµ‹çš„æ•°æ®è¯»å–è·Ÿå›¾åƒåˆ†ç±»çš„ç±»ä¼¼ã€‚ç„¶è€Œï¼Œåœ¨å¼•å…¥è¾¹ç•Œæ¡†åï¼Œæ ‡ç­¾å½¢çŠ¶å’Œå›¾åƒå¢å¹¿ï¼ˆå¦‚éšæœºè£å‰ªï¼‰å‘ç”Ÿäº†å˜åŒ–ã€‚
